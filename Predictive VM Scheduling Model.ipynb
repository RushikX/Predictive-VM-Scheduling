{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c87DGr7pfDgk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a6d536b-44e6-4f8b-c26a-7730cb6820bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.2)\n",
            "Collecting simpy\n",
            "  Downloading simpy-4.1.1-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (3.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading simpy-4.1.1-py3-none-any.whl (27 kB)\n",
            "Installing collected packages: simpy\n",
            "Successfully installed simpy-4.1.1\n"
          ]
        }
      ],
      "source": [
        "# ===========================\n",
        "# 1.Requirements\n",
        "# ===========================\n",
        "try:\n",
        "    import numpy as np, pandas as pd, matplotlib, sklearn, simpy, networkx, tqdm, scipy\n",
        "except ImportError as e:\n",
        "    !pip install numpy pandas matplotlib scikit-learn scipy simpy networkx tqdm\n",
        "\n",
        "# Optional\n",
        "try:\n",
        "    import xgboost\n",
        "except ImportError:\n",
        "    try:\n",
        "        !pip install xgboost\n",
        "    except:\n",
        "        xgboost = None\n",
        "\n",
        "try:\n",
        "    import optuna\n",
        "except ImportError:\n",
        "    optuna = None\n",
        "\n",
        "import os, random, json, math, time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "import simpy\n",
        "from tqdm import tqdm\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
        "from scipy import stats"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 2.CONFIG\n",
        "# ===========================\n",
        "CONFIG = {\n",
        "    \"SEED\": 42,\n",
        "    \"SMOKE_TEST\": False,   # Set True for 1-min run\n",
        "    \"NUM_TASKS\": 50000,\n",
        "    \"NUM_VMS\": 300,\n",
        "    \"RUNTIME_MINUTES\": 120,\n",
        "    \"SCHED_TICK_MS\": 250,\n",
        "    \"TRAIN_WARMUP_TASKS\": 2000,\n",
        "    \"ONLINE_UPDATE_FREQ\": 200,\n",
        "    \"RESULTS_DIR\": \"/content\" if os.path.exists(\"/content\") else \"./artifacts\",\n",
        "}\n",
        "\n",
        "if CONFIG[\"SMOKE_TEST\"]:\n",
        "    CONFIG.update({\n",
        "        \"NUM_TASKS\": 2000,\n",
        "        \"NUM_VMS\": 20,\n",
        "        \"RUNTIME_MINUTES\": 10,\n",
        "    })\n",
        "\n",
        "os.makedirs(CONFIG[\"RESULTS_DIR\"], exist_ok=True)\n",
        "np.random.seed(CONFIG[\"SEED\"])\n",
        "random.seed(CONFIG[\"SEED\"])"
      ],
      "metadata": {
        "id": "pLKOpr0-fQ7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 3) Synthetic Workload Generator\n",
        "# ===========================\n",
        "\n",
        "def generate_vms(num_vms, seed=0, pattern=None):\n",
        "    np.random.seed(seed)\n",
        "    vms = []\n",
        "    for i in range(num_vms):\n",
        "        if pattern == \"heterogeneous\":\n",
        "            cores = np.random.choice([2, 4, 8, 16, 32])\n",
        "            ghz = max(1.0, np.random.normal(loc=np.random.choice([1.8, 2.5, 3.5]), scale=0.7))\n",
        "            mem = np.random.choice([2, 4, 8, 16, 32, 64])\n",
        "            iops = np.random.lognormal(mean=2.5 + np.random.rand(), sigma=0.9)\n",
        "            arch = np.random.choice([\"x86\", \"ARM\", \"RISC\"])\n",
        "            loc = np.random.choice([\"edge\", \"cloud\"], p=[0.6, 0.4])\n",
        "        else:\n",
        "            cores = np.random.choice([2, 4, 8, 16])\n",
        "            ghz = max(1.0, np.random.normal(loc=2.5, scale=0.5))\n",
        "            mem = np.random.choice([4, 8, 16, 32])\n",
        "            iops = np.random.lognormal(mean=3, sigma=0.5)\n",
        "            arch = np.random.choice([\"x86\", \"ARM\"])\n",
        "            loc = \"edge\" if np.random.rand() < 0.6 else \"cloud\"\n",
        "        vms.append([i, cores, ghz, mem, iops, arch, loc])\n",
        "    return pd.DataFrame(vms, columns=[\"vm_id\", \"cores\", \"cpu_ghz\", \"mem_gb\", \"disk_iops\", \"arch\", \"loc\"])\n",
        "\n",
        "def generate_tasks(num_tasks, runtime_minutes, seed=0, pattern=None):\n",
        "    np.random.seed(seed)\n",
        "    arrivals = np.cumsum(np.random.poisson(lam=5, size=num_tasks)) % (runtime_minutes*60)\n",
        "    tasks = []\n",
        "    types = [\"batch\", \"interactive\", \"ml\"]\n",
        "    for i in range(num_tasks):\n",
        "        if pattern == \"bursty\":\n",
        "            if i % 500 < 400:\n",
        "                arrivals[i] += np.random.normal(0, 10)\n",
        "        # Clamp arrival time >= 0 to prevent simulation errors\n",
        "        arrivals[i] = max(0, arrivals[i])\n",
        "\n",
        "        cpu = np.random.lognormal(mean=3, sigma=1)\n",
        "        mem = np.random.choice([1, 2, 4, 8])\n",
        "        io = np.clip(np.random.beta(2, 5) + (0.3 if pattern == \"heterogeneous\" and i % 2 == 0 else 0), 0, 1)\n",
        "        size = np.random.exponential(scale=50 if pattern != \"heterogeneous\" else 100)\n",
        "        deadline = arrivals[i] + np.random.uniform(10, 100) if np.random.rand() < 0.3 else None\n",
        "        ilp = np.random.uniform(0.5, 2.0)\n",
        "        ttype = np.random.choice(types)\n",
        "        tasks.append([i, arrivals[i], cpu, mem, io, size, deadline, ilp, ttype])\n",
        "    return pd.DataFrame(tasks, columns=[\"task_id\", \"arrival\", \"cpu_req\", \"mem_req\", \"io_intensity\", \"input_mb\", \"deadline\", \"ilp\", \"type\"])\n",
        "\n",
        "# Example for testing:\n",
        "vms_df = generate_vms(CONFIG[\"NUM_VMS\"], CONFIG[\"SEED\"], pattern=\"heterogeneous\")\n",
        "tasks_df = generate_tasks(CONFIG[\"NUM_TASKS\"], CONFIG[\"RUNTIME_MINUTES\"], CONFIG[\"SEED\"], pattern=\"bursty\")\n",
        "\n",
        "print(\"VMs preview:\\n\", vms_df.head())\n",
        "print(\"Tasks preview:\\n\", tasks_df.head())\n",
        "\n",
        "assert len(vms_df)>0 and len(tasks_df)>0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0D2GRU-4fqJB",
        "outputId": "70a19630-8ec8-43ac-f530-1fcd626973bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VMs preview:\n",
            "    vm_id  cores   cpu_ghz  mem_gb  disk_iops  arch    loc\n",
            "0      0     16  2.180620      32   8.183598  RISC   edge\n",
            "1      1      8  2.905449      64  25.715729   ARM   edge\n",
            "2      2     16  2.823665      32  74.947547   x86   edge\n",
            "3      3      4  4.525954       8  14.574353   x86   edge\n",
            "4      4      8  3.079822      32  36.002546  RISC  cloud\n",
            "Tasks preview:\n",
            "    task_id  arrival    cpu_req  mem_req  io_intensity   input_mb    deadline  \\\n",
            "0        0       11  32.786512        8      0.237605   7.017056         NaN   \n",
            "1        1       17  43.767978        4      0.582252  22.698222   98.623023   \n",
            "2        2       12  15.284867        2      0.203930  39.212414         NaN   \n",
            "3        3        8  16.645953        8      0.106794  15.368639         NaN   \n",
            "4        4       22   9.997307        1      0.586072   2.476741  119.423401   \n",
            "\n",
            "        ilp         type  \n",
            "0  1.412203        batch  \n",
            "1  1.895989  interactive  \n",
            "2  1.592084  interactive  \n",
            "3  1.456554           ml  \n",
            "4  1.136708  interactive  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# 4) Discrete-Event Simulation\n",
        "# ===============================\n",
        "\n",
        "class Task:\n",
        "    \"\"\"Represents a submitted task in the system.\"\"\"\n",
        "    def __init__(self, row):\n",
        "        self.task_id = row.task_id\n",
        "        self.arrival = row.arrival\n",
        "        self.cpu_req = row.cpu_req\n",
        "        self.mem_req = row.mem_req\n",
        "        self.io_intensity = row.io_intensity\n",
        "        self.input_mb = row.input_mb\n",
        "        self.deadline = row.deadline\n",
        "        self.ilp = row.ilp\n",
        "        self.type = row.type\n",
        "        # Runtime stats\n",
        "        self.wait_time = None\n",
        "        self.start_time = None\n",
        "        self.finish_time = None\n",
        "        self.vm_id = None\n",
        "        self.transfer_time = None\n",
        "        self.compute_time = None\n",
        "\n",
        "class VM:\n",
        "    \"\"\"Resource model of a VM (single-task capacity for simplicity).\"\"\"\n",
        "    def __init__(self,row):\n",
        "        self.vm_id = row.vm_id\n",
        "        self.cores = row.cores\n",
        "        self.cpu_ghz = row.cpu_ghz\n",
        "        self.mem_gb = row.mem_gb\n",
        "        self.disk_iops = row.disk_iops\n",
        "        self.arch = row.arch\n",
        "        self.loc = row.loc\n",
        "        self.busy_until = 0.0\n",
        "\n",
        "    def is_free(self, now):\n",
        "        return now >= self.busy_until\n",
        "\n",
        "class NetworkModel:\n",
        "    \"\"\"Simplified network model with dynamic latency and bandwidth.\"\"\"\n",
        "    def __init__(self, seed=0):\n",
        "        np.random.seed(seed)\n",
        "        self.base_latency = {\"edge\":10, \"cloud\":50}\n",
        "        self.base_bw = {\"edge\":100, \"cloud\":1000} # Mbps\n",
        "\n",
        "    def transfer_time(self, src_loc, dst_loc, mb, now):\n",
        "        lat = self.base_latency[dst_loc] * (1 + 0.1*np.sin(now/600))\n",
        "        bw = self.base_bw[dst_loc] * (0.8+0.4*np.sin(now/300))\n",
        "        bw = max(10,bw)\n",
        "        return lat/1000 + (mb*8)/bw # latency + transmission\n",
        "\n",
        "class Simulator:\n",
        "    \"\"\"SimPy-based simulator with scheduler plug-in.\"\"\"\n",
        "    def __init__(self, tasks_df, vms_df, scheduler_cls, config):\n",
        "        self.env = simpy.Environment()\n",
        "        self.tasks = [Task(r) for r in tasks_df.itertuples()]\n",
        "        self.vms = {r.vm_id:VM(r) for r in vms_df.itertuples()}\n",
        "        self.scheduler = scheduler_cls(self, config)\n",
        "        self.config = config\n",
        "        self.now = 0\n",
        "        self.queue=[]\n",
        "        self.completed=[]\n",
        "        self.net_model = NetworkModel(config['SEED'])\n",
        "\n",
        "    def run(self):\n",
        "        # Task arrivals\n",
        "        for task in self.tasks:\n",
        "            self.env.process(self.task_arrival(task))\n",
        "        # Scheduler loop\n",
        "        self.env.process(self.schedule_loop())\n",
        "        self.env.run(until=self.config[\"RUNTIME_MINUTES\"]*60)\n",
        "\n",
        "    def task_arrival(self, task):\n",
        "        yield self.env.timeout(task.arrival)\n",
        "        self.queue.append(task)\n",
        "\n",
        "    def schedule_loop(self):\n",
        "        while True:\n",
        "            yield self.env.timeout(self.config[\"SCHED_TICK_MS\"]/1000)\n",
        "            self.now=self.env.now\n",
        "            self.scheduler.schedule(self.now)\n",
        "\n",
        "    def start_task(self,task,vm,now):\n",
        "        \"\"\"Allocate task to VM if free and schedule its completion.\"\"\"\n",
        "        if not vm.is_free(now):\n",
        "            return False\n",
        "        transfer = self.net_model.transfer_time(\"edge\", vm.loc, task.input_mb, now)\n",
        "        # Hidden ground-truth runtime function\n",
        "        base = task.cpu_req/(vm.cores*vm.cpu_ghz*task.ilp)\n",
        "        noise = np.random.lognormal(mean=0, sigma=0.25)\n",
        "        runtime = base*noise*(1+0.1*task.io_intensity)\n",
        "        task.wait_time = now-task.arrival\n",
        "        task.start_time = now+transfer\n",
        "        task.transfer_time=transfer\n",
        "        task.compute_time=runtime\n",
        "        task.vm_id=vm.vm_id\n",
        "        task.finish_time = task.start_time+runtime\n",
        "        vm.busy_until = task.finish_time\n",
        "        self.completed.append(task)\n",
        "        return True\n",
        "\n",
        "# Sanity test\n",
        "test_sim = Simulator(tasks_df.head(1000), vms_df.head(100), scheduler_cls=lambda sim, cfg: None, config=CONFIG)\n",
        "print(\"Simulator initialized with\", len(test_sim.tasks), \"tasks and\", len(test_sim.vms), \"VMs\")\n",
        "assert isinstance(test_sim.tasks[0], Task)\n",
        "assert isinstance(test_sim.vms[0], VM)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyWsV-Swft-3",
        "outputId": "5d462abc-311c-4f09-f982-061251330094"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Simulator initialized with 1000 tasks and 100 VMs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# 5) Baseline Schedulers\n",
        "# ===============================\n",
        "\n",
        "class BaseScheduler:\n",
        "    \"\"\"Abstract scheduler interface.\"\"\"\n",
        "    def __init__(self, sim:Simulator, config):\n",
        "        self.sim=sim\n",
        "        self.config=config\n",
        "\n",
        "    def schedule(self, now):\n",
        "        raise NotImplementedError\n",
        "\n",
        "class RandomScheduler(BaseScheduler):\n",
        "    def schedule(self, now):\n",
        "        for task in list(self.sim.queue):\n",
        "            free_vms=[vm for vm in self.sim.vms.values() if vm.is_free(now)]\n",
        "            if not free_vms: return\n",
        "            vm=random.choice(free_vms)\n",
        "            if self.sim.start_task(task,vm,now):\n",
        "                self.sim.queue.remove(task)\n",
        "\n",
        "class FCFS(BaseScheduler):\n",
        "    def schedule(self,now):\n",
        "        if not self.sim.queue: return\n",
        "        free_vms=[vm for vm in self.sim.vms.values() if vm.is_free(now)]\n",
        "        for vm in free_vms:\n",
        "            if not self.sim.queue: return\n",
        "            task=self.sim.queue[0]\n",
        "            if self.sim.start_task(task,vm,now):\n",
        "                self.sim.queue.remove(task)\n",
        "\n",
        "class RoundRobin(BaseScheduler):\n",
        "    def __init__(self,sim,config):\n",
        "        super().__init__(sim,config)\n",
        "        self.idx=0\n",
        "        self.vm_ids=list(sim.vms.keys())\n",
        "    def schedule(self,now):\n",
        "        for task in list(self.sim.queue):\n",
        "            for _ in range(len(self.vm_ids)):\n",
        "                vm=self.sim.vms[self.vm_ids[self.idx]]\n",
        "                self.idx=(self.idx+1)%len(self.vm_ids)\n",
        "                if vm.is_free(now):\n",
        "                    if self.sim.start_task(task,vm,now):\n",
        "                        self.sim.queue.remove(task)\n",
        "                        break\n",
        "\n",
        "class MinMin(BaseScheduler):\n",
        "    def schedule(self,now):\n",
        "        tasks=list(self.sim.queue)\n",
        "        free_vms=[vm for vm in self.sim.vms.values() if vm.is_free(now)]\n",
        "        for t in tasks:\n",
        "            if not free_vms: return\n",
        "            est=[(vm, t.cpu_req/(vm.cores*vm.cpu_ghz*t.ilp)) for vm in free_vms]\n",
        "            vm=min(est,key=lambda x:x[1])[0]\n",
        "            if self.sim.start_task(t,vm,now):\n",
        "                self.sim.queue.remove(t)\n",
        "\n",
        "class MaxMin(BaseScheduler):\n",
        "    def schedule(self,now):\n",
        "        tasks=list(self.sim.queue)\n",
        "        free_vms=[vm for vm in self.sim.vms.values() if vm.is_free(now)]\n",
        "        for t in tasks:\n",
        "            if not free_vms: return\n",
        "            est=[(vm, t.cpu_req/(vm.cores*vm.cpu_ghz*t.ilp)) for vm in free_vms]\n",
        "            vm=max(est,key=lambda x:x[1])[0]\n",
        "            if self.sim.start_task(t,vm,now):\n",
        "                self.sim.queue.remove(t)\n",
        "\n",
        "# Sanity check\n",
        "test_sim = Simulator(tasks_df.head(50), vms_df.head(5), scheduler_cls=RandomScheduler, config=CONFIG)\n",
        "test_sim.run()\n",
        "print(\"Completed\", len(test_sim.completed),\"tasks in quick sanity sim\")\n",
        "assert len(test_sim.completed)>0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4pw4YKQf1yt",
        "outputId": "783e8dcd-749e-479a-9c51-b8f3d01a845f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 50 tasks in quick sanity sim\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# 6) Hybrid Predictive Scheduler\n",
        "# ===============================\n",
        "\n",
        "\n",
        "class HybridScheduler(BaseScheduler):\n",
        "    def __init__(self, sim, config):\n",
        "        super().__init__(sim, config)\n",
        "        self.scaler = StandardScaler()\n",
        "        self.model = GradientBoostingRegressor(\n",
        "            n_estimators=120, max_depth=4, learning_rate=0.07, random_state=config[\"SEED\"]\n",
        "        )\n",
        "        self.history_X = []\n",
        "        self.history_y = []\n",
        "        self.is_model_ready = False\n",
        "        self.warmup_count = config.get(\"TRAIN_WARMUP_TASKS\", 1000)\n",
        "        self.online_update_freq = config.get(\"ONLINE_UPDATE_FREQ\", 100)\n",
        "\n",
        "    # Robust feature extractor - cleans NaNs/infs\n",
        "    def feature_vector(self, task, vm, now):\n",
        "        cpu_util = task.cpu_req / (vm.cores * vm.cpu_ghz + 1e-6)\n",
        "        mem_util = task.mem_req / (vm.mem_gb + 1e-6)\n",
        "        io_vs_disk = task.io_intensity / (vm.disk_iops + 1e-6)\n",
        "        input_log = np.log1p(task.input_mb)\n",
        "        tod = (now % 86400) / 86400.0\n",
        "        deadline_feat = (task.deadline - now) if (task.deadline is not None and not np.isnan(task.deadline)) else -1\n",
        "        features = np.array([\n",
        "            task.cpu_req, task.mem_req, task.io_intensity, input_log,\n",
        "            int(task.type==\"ml\"), int(task.type==\"batch\"), int(task.type==\"interactive\"),\n",
        "            task.ilp,\n",
        "            vm.cores, vm.cpu_ghz, vm.mem_gb, vm.disk_iops,\n",
        "            int(vm.arch==\"arm\"), int(vm.loc==\"cloud\"),\n",
        "            cpu_util, mem_util, io_vs_disk, tod, np.sin(2*np.pi*tod), np.cos(2*np.pi*tod),\n",
        "            deadline_feat\n",
        "        ])\n",
        "        features = np.nan_to_num(features, nan=-1, posinf=-1, neginf=-1)\n",
        "        return features\n",
        "\n",
        "    def schedule(self, now):\n",
        "        free_vms = [vm for vm in self.sim.vms.values() if vm.is_free(now)]\n",
        "        if not self.sim.queue or not free_vms:\n",
        "            return\n",
        "\n",
        "        for task in list(self.sim.queue):\n",
        "            if not self.is_model_ready:\n",
        "                est = [\n",
        "                    (vm, task.cpu_req / (vm.cores * vm.cpu_ghz * (task.ilp if task.ilp > 0 else 1)))\n",
        "                    for vm in free_vms\n",
        "                ]\n",
        "                vm = min(est, key=lambda x: x[1])[0]\n",
        "                if self.sim.start_task(task, vm, now):\n",
        "                    self.sim.queue.remove(task)\n",
        "                    X = self.feature_vector(task, vm, now)\n",
        "                    y = task.compute_time\n",
        "                    if not np.isnan(X).any() and not np.isnan(y):\n",
        "                        self.history_X.append(X)\n",
        "                        self.history_y.append(y)\n",
        "                if len(self.history_X) >= self.warmup_count and not self.is_model_ready:\n",
        "                    Xarr = np.vstack(self.history_X)\n",
        "                    yarr = np.array(self.history_y)\n",
        "                    valid_rows = ~np.isnan(Xarr).any(axis=1) & ~np.isnan(yarr)\n",
        "                    Xarr = Xarr[valid_rows]\n",
        "                    yarr = yarr[valid_rows]\n",
        "                    self.scaler.fit(Xarr)\n",
        "                    self.model.fit(self.scaler.transform(Xarr), yarr)\n",
        "                    self.is_model_ready = True\n",
        "                    print(f\"[HybridScheduler] Model trained at t={now} with {len(Xarr)} samples.\")\n",
        "                continue\n",
        "\n",
        "            preds = []\n",
        "            for vm in free_vms:\n",
        "                features = self.feature_vector(task, vm, now)\n",
        "                if np.isnan(features).any():\n",
        "                    continue\n",
        "                try:\n",
        "                    X_scaled = self.scaler.transform([features])\n",
        "                    pred = self.model.predict(X_scaled)[0]\n",
        "                except Exception as e:\n",
        "                    print(f\"Prediction error: {e}\")\n",
        "                    pred = 1e9\n",
        "                transfer = self.sim.net_model.transfer_time(\"edge\", vm.loc, task.input_mb, now)\n",
        "                total_time = pred + transfer\n",
        "                preds.append((vm, total_time))\n",
        "            if not preds:\n",
        "                continue\n",
        "            vm = min(preds, key=lambda p: p[1])[0]\n",
        "            if self.sim.start_task(task, vm, now):\n",
        "                self.sim.queue.remove(task)\n",
        "                X = self.feature_vector(task, vm, now)\n",
        "                y = task.compute_time\n",
        "                if not np.isnan(X).any() and not np.isnan(y):\n",
        "                    self.history_X.append(X)\n",
        "                    self.history_y.append(y)\n",
        "                if len(self.history_X) % self.online_update_freq == 0:\n",
        "                    Xarr = np.vstack(self.history_X)\n",
        "                    yarr = np.array(self.history_y)\n",
        "                    valid_rows = ~np.isnan(Xarr).any(axis=1) & ~np.isnan(yarr)\n",
        "                    Xarr = Xarr[valid_rows]\n",
        "                    yarr = yarr[valid_rows]\n",
        "                    self.scaler.fit(Xarr)\n",
        "                    self.model.fit(self.scaler.transform(Xarr), yarr)\n",
        "                    print(f\"[HybridScheduler] Online update at t={now} ({len(Xarr)} samples)\")\n",
        "\n"
      ],
      "metadata": {
        "id": "mjKdzRhrf3_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# 7) Training & Online Learning Diagnostics (Fixed)\n",
        "# ===============================\n",
        "def compute_prediction_error(history_X, history_y, model, scaler):\n",
        "    if len(history_X) < 50:\n",
        "        return None\n",
        "    X = np.vstack(history_X)\n",
        "    y = np.array(history_y)\n",
        "    valid_rows = ~np.isnan(X).any(axis=1) & ~np.isnan(y)\n",
        "    X = X[valid_rows]\n",
        "    y = y[valid_rows]\n",
        "    if len(X) == 0 or len(y) == 0:\n",
        "        return None\n",
        "    Xs = scaler.transform(X)\n",
        "    yhat = model.predict(Xs)\n",
        "    mae = mean_absolute_error(y, yhat)\n",
        "    mape = mean_absolute_percentage_error(y, yhat)\n",
        "    return mae, mape\n",
        "\n",
        "def stable_compute_learning_curve(hybrid_scheduler, outdir, model_params=None):\n",
        "    errs = []\n",
        "    winsize = 200\n",
        "    n = len(hybrid_scheduler.history_X)\n",
        "    for i in range(winsize, n, winsize):\n",
        "        try:\n",
        "            X = np.vstack(hybrid_scheduler.history_X[:i])\n",
        "            y = np.array(hybrid_scheduler.history_y[:i])\n",
        "            valid_rows = ~np.isnan(X).any(axis=1) & ~np.isnan(y)\n",
        "            X = X[valid_rows]\n",
        "            y = y[valid_rows]\n",
        "            if len(X) < 50:\n",
        "                continue\n",
        "            scaler = StandardScaler()\n",
        "            scaler.fit(X)\n",
        "            if model_params is None:\n",
        "                model = GradientBoostingRegressor(n_estimators=120, max_depth=4, learning_rate=0.07)\n",
        "            else:\n",
        "                model = GradientBoostingRegressor(**model_params)\n",
        "            model.fit(scaler.transform(X), y)\n",
        "            yhat = model.predict(scaler.transform(X))\n",
        "            mae = mean_absolute_error(y, yhat)\n",
        "            mape = mean_absolute_percentage_error(y, yhat)\n",
        "            errs.append((i, mae, mape))\n",
        "        except Exception as e:\n",
        "            print(f\"Diagnostic fitting failed at {i} samples: {e}\")\n",
        "    errs = pd.DataFrame(errs, columns=[\"num\", \"mae\", \"mape\"])\n",
        "    if errs.empty:\n",
        "        print(\"No diagnostics computed.\")\n",
        "    else:\n",
        "        plt.figure(figsize=(6, 4))\n",
        "        plt.plot(errs[\"num\"], errs[\"mae\"], label=\"MAE\")\n",
        "        plt.plot(errs[\"num\"], errs[\"mape\"], label=\"MAPE\")\n",
        "        plt.xlabel(\"Training samples\")\n",
        "        plt.ylabel(\"Error\")\n",
        "        plt.legend()\n",
        "        plt.title(\"Prediction Error over Online Training\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(outdir, \"learning_curve.png\"))\n",
        "        plt.close()\n",
        "    return errs\n"
      ],
      "metadata": {
        "id": "y7VUpJiqf6gj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WsExOs6-vR18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# 8) Evaluation Protocol\n",
        "# ===============================\n",
        "SCENARIOS = {\n",
        "    \"stationary\": {\n",
        "        \"NUM_TASKS\": 3000, \"NUM_VMS\": 50, \"RUNTIME_MINUTES\": 30,\n",
        "        \"PATTERN\": \"stationary\"\n",
        "    },\n",
        "    \"bursty\": {\n",
        "        \"NUM_TASKS\": 3000, \"NUM_VMS\": 50, \"RUNTIME_MINUTES\": 30,\n",
        "        \"PATTERN\": \"bursty\"\n",
        "    },\n",
        "    \"heterogeneous\": {\n",
        "        \"NUM_TASKS\": 3000, \"NUM_VMS\": 50, \"RUNTIME_MINUTES\": 30,\n",
        "        \"PATTERN\": \"heterogeneous\"\n",
        "    }\n",
        "}\n",
        "SCHEDULERS = {\n",
        "    \"Random\": RandomScheduler,\n",
        "    \"FCFS\": FCFS,\n",
        "    \"RoundRobin\": RoundRobin,\n",
        "    \"MinMin\": MinMin,\n",
        "    \"MaxMin\": MaxMin,\n",
        "    \"Proposed Method\": HybridScheduler,\n",
        "}\n",
        "\n",
        "\n",
        "def run_experiment(scenario_name, config, seed):\n",
        "    cfg = config.copy()\n",
        "    cfg.update(SCENARIOS[scenario_name])\n",
        "    cfg[\"SEED\"] = seed + hash(scenario_name) % 10000  # Unique seed per scenario\n",
        "    np.random.seed(cfg[\"SEED\"])\n",
        "    random.seed(cfg[\"SEED\"])\n",
        "    tasks = generate_tasks(cfg[\"NUM_TASKS\"], cfg[\"RUNTIME_MINUTES\"], cfg[\"SEED\"], pattern=cfg.get(\"PATTERN\"))\n",
        "    vms = generate_vms(cfg[\"NUM_VMS\"], cfg[\"SEED\"], pattern=cfg.get(\"PATTERN\"))\n",
        "    results = []\n",
        "    for sname, Scls in SCHEDULERS.items():\n",
        "        sim = Simulator(tasks, vms, Scls, cfg)\n",
        "        sim.run()\n",
        "        completion = [t.finish_time - t.arrival for t in sim.completed if t.finish_time]\n",
        "        act = np.mean(completion)\n",
        "        makespan = max([t.finish_time for t in sim.completed]) - min([t.start_time for t in sim.completed])\n",
        "        p95 = np.percentile(completion, 95)\n",
        "        deadline_miss = np.mean([1 if t.deadline and t.finish_time > t.deadline else 0 for t in sim.completed])\n",
        "        results.append([scenario_name, sname, act, makespan, p95, deadline_miss])\n",
        "    return pd.DataFrame(results, columns=[\"scenario\", \"scheduler\", \"ACT\", \"makespan\", \"p95\", \"deadline_miss\"])\n",
        "\n",
        "# Sanity: small run\n",
        "res=run_experiment(\"heterogeneous\",CONFIG,seed=5)\n",
        "print(res)\n",
        "assert not res.empty\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrMkAGA0gB76",
        "outputId": "87f91f9d-572f-44d1-8338-3dd49d84bcb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[HybridScheduler] Model trained at t=1181.5 with 2000 samples.\n",
            "[HybridScheduler] Online update at t=1309.25 (2200 samples)\n",
            "[HybridScheduler] Online update at t=1431.0 (2400 samples)\n",
            "[HybridScheduler] Online update at t=1548.25 (2600 samples)\n",
            "[HybridScheduler] Online update at t=1674.5 (2800 samples)\n",
            "[HybridScheduler] Online update at t=1799.0 (3000 samples)\n",
            "        scenario        scheduler       ACT     makespan        p95  \\\n",
            "0  heterogeneous           Random  7.466872  1813.648103  27.575907   \n",
            "1  heterogeneous             FCFS  4.395901  1854.014036  17.857155   \n",
            "2  heterogeneous       RoundRobin  7.518895  1854.151337  27.331590   \n",
            "3  heterogeneous           MinMin  2.439951  1853.883388   6.789912   \n",
            "4  heterogeneous           MaxMin  9.865537  1833.374952  31.772320   \n",
            "5  heterogeneous  Proposed Method  2.158059  1801.233032   5.630134   \n",
            "\n",
            "   deadline_miss  \n",
            "0       0.009667  \n",
            "1       0.004000  \n",
            "2       0.008333  \n",
            "3       0.000667  \n",
            "4       0.011000  \n",
            "5       0.000000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# 9) Batch Experiments Across Scenarios\n",
        "# ===============================\n",
        "\n",
        "all_results=[]\n",
        "for sc in SCENARIOS:\n",
        "    for seed in range(5): # keep small for demo; in full run use 5 seeds\n",
        "        df=run_experiment(sc,CONFIG,seed)\n",
        "        all_results.append(df)\n",
        "all_results=pd.concat(all_results,ignore_index=True)\n",
        "\n",
        "agg=all_results.groupby([\"scenario\",\"scheduler\"]).agg([\"mean\",\"std\"])\n",
        "print(agg)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c7lEgjKk8eh",
        "outputId": "6cb947c7-63c8-48b0-d7df-afdcf7f04e10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[HybridScheduler] Model trained at t=1168.0 with 2000 samples.\n",
            "[HybridScheduler] Online update at t=1287.0 (2200 samples)\n",
            "[HybridScheduler] Online update at t=1422.0 (2400 samples)\n",
            "[HybridScheduler] Online update at t=1551.0 (2600 samples)\n",
            "[HybridScheduler] Online update at t=1673.25 (2800 samples)\n",
            "[HybridScheduler] Online update at t=1799.75 (3000 samples)\n",
            "[HybridScheduler] Model trained at t=1178.25 with 2000 samples.\n",
            "[HybridScheduler] Online update at t=1303.0 (2200 samples)\n",
            "[HybridScheduler] Online update at t=1426.0 (2400 samples)\n",
            "[HybridScheduler] Online update at t=1552.0 (2600 samples)\n",
            "[HybridScheduler] Online update at t=1676.0 (2800 samples)\n",
            "[HybridScheduler] Online update at t=1799.25 (3000 samples)\n",
            "[HybridScheduler] Model trained at t=1187.0 with 2000 samples.\n",
            "[HybridScheduler] Online update at t=1301.0 (2200 samples)\n",
            "[HybridScheduler] Online update at t=1424.0 (2400 samples)\n",
            "[HybridScheduler] Online update at t=1544.25 (2600 samples)\n",
            "[HybridScheduler] Online update at t=1672.0 (2800 samples)\n",
            "[HybridScheduler] Online update at t=1799.0 (3000 samples)\n",
            "[HybridScheduler] Model trained at t=1187.25 with 2000 samples.\n",
            "[HybridScheduler] Online update at t=1309.0 (2200 samples)\n",
            "[HybridScheduler] Online update at t=1429.25 (2400 samples)\n",
            "[HybridScheduler] Online update at t=1552.0 (2600 samples)\n",
            "[HybridScheduler] Online update at t=1672.25 (2800 samples)\n",
            "[HybridScheduler] Online update at t=1798.25 (3000 samples)\n",
            "[HybridScheduler] Model trained at t=1179.25 with 2000 samples.\n",
            "[HybridScheduler] Online update at t=1300.0 (2200 samples)\n",
            "[HybridScheduler] Online update at t=1425.0 (2400 samples)\n",
            "[HybridScheduler] Online update at t=1550.0 (2600 samples)\n",
            "[HybridScheduler] Online update at t=1679.0 (2800 samples)\n",
            "[HybridScheduler] Online update at t=1799.0 (3000 samples)\n",
            "[HybridScheduler] Model trained at t=1174.25 with 2000 samples.\n",
            "[HybridScheduler] Online update at t=1307.0 (2200 samples)\n",
            "[HybridScheduler] Online update at t=1434.0 (2400 samples)\n",
            "[HybridScheduler] Online update at t=1552.25 (2600 samples)\n",
            "[HybridScheduler] Online update at t=1684.0 (2800 samples)\n",
            "[HybridScheduler] Model trained at t=1195.5 with 2000 samples.\n",
            "[HybridScheduler] Online update at t=1312.0 (2200 samples)\n",
            "[HybridScheduler] Online update at t=1429.25 (2400 samples)\n",
            "[HybridScheduler] Online update at t=1553.5 (2600 samples)\n",
            "[HybridScheduler] Online update at t=1679.25 (2800 samples)\n",
            "[HybridScheduler] Model trained at t=1178.0 with 2000 samples.\n",
            "[HybridScheduler] Online update at t=1301.25 (2200 samples)\n",
            "[HybridScheduler] Online update at t=1421.25 (2400 samples)\n",
            "[HybridScheduler] Online update at t=1548.5 (2600 samples)\n",
            "[HybridScheduler] Online update at t=1669.0 (2800 samples)\n",
            "[HybridScheduler] Model trained at t=1176.0 with 2000 samples.\n",
            "[HybridScheduler] Online update at t=1303.0 (2200 samples)\n",
            "[HybridScheduler] Online update at t=1429.0 (2400 samples)\n",
            "[HybridScheduler] Online update at t=1552.0 (2600 samples)\n",
            "[HybridScheduler] Online update at t=1678.0 (2800 samples)\n",
            "[HybridScheduler] Model trained at t=1186.0 with 2000 samples.\n",
            "[HybridScheduler] Online update at t=1304.25 (2200 samples)\n",
            "[HybridScheduler] Online update at t=1427.0 (2400 samples)\n",
            "[HybridScheduler] Online update at t=1548.25 (2600 samples)\n",
            "[HybridScheduler] Online update at t=1676.5 (2800 samples)\n",
            "[HybridScheduler] Model trained at t=1178.5 with 2000 samples.\n",
            "[HybridScheduler] Online update at t=1303.5 (2200 samples)\n",
            "[HybridScheduler] Online update at t=1427.0 (2400 samples)\n",
            "[HybridScheduler] Online update at t=1556.0 (2600 samples)\n",
            "[HybridScheduler] Online update at t=1677.25 (2800 samples)\n",
            "[HybridScheduler] Online update at t=1799.0 (3000 samples)\n",
            "[HybridScheduler] Model trained at t=1163.0 with 2000 samples.\n",
            "[HybridScheduler] Online update at t=1290.25 (2200 samples)\n",
            "[HybridScheduler] Online update at t=1417.0 (2400 samples)\n",
            "[HybridScheduler] Online update at t=1543.25 (2600 samples)\n",
            "[HybridScheduler] Online update at t=1673.0 (2800 samples)\n",
            "[HybridScheduler] Online update at t=1799.25 (3000 samples)\n",
            "[HybridScheduler] Model trained at t=1159.25 with 2000 samples.\n",
            "[HybridScheduler] Online update at t=1285.0 (2200 samples)\n",
            "[HybridScheduler] Online update at t=1419.0 (2400 samples)\n",
            "[HybridScheduler] Online update at t=1541.0 (2600 samples)\n",
            "[HybridScheduler] Online update at t=1673.25 (2800 samples)\n",
            "[HybridScheduler] Online update at t=1799.0 (3000 samples)\n",
            "[HybridScheduler] Model trained at t=1160.5 with 2000 samples.\n",
            "[HybridScheduler] Online update at t=1284.25 (2200 samples)\n",
            "[HybridScheduler] Online update at t=1412.0 (2400 samples)\n",
            "[HybridScheduler] Online update at t=1545.0 (2600 samples)\n",
            "[HybridScheduler] Online update at t=1670.0 (2800 samples)\n",
            "[HybridScheduler] Online update at t=1799.5 (3000 samples)\n",
            "[HybridScheduler] Model trained at t=1150.0 with 2000 samples.\n",
            "[HybridScheduler] Online update at t=1284.0 (2200 samples)\n",
            "[HybridScheduler] Online update at t=1410.0 (2400 samples)\n",
            "[HybridScheduler] Online update at t=1539.0 (2600 samples)\n",
            "[HybridScheduler] Online update at t=1674.0 (2800 samples)\n",
            "[HybridScheduler] Online update at t=1799.25 (3000 samples)\n",
            "                                    ACT               makespan             \\\n",
            "                                   mean       std         mean        std   \n",
            "scenario      scheduler                                                     \n",
            "bursty        FCFS             5.925543  0.542387  1831.144744  15.672446   \n",
            "              MaxMin           8.922854  0.517230  1852.556724  55.591338   \n",
            "              MinMin           2.957443  0.372528  1810.033626  12.357395   \n",
            "              Proposed Method  2.324566  0.209719  1799.958265   1.386682   \n",
            "              Random           6.324835  0.447692  1830.108106   9.375714   \n",
            "              RoundRobin       6.685452  0.391859  1845.827346  16.293194   \n",
            "heterogeneous FCFS             5.160597  1.930900  1827.784816  15.757596   \n",
            "              MaxMin           9.858083  1.009043  1847.109397  11.000321   \n",
            "              MinMin           3.361680  0.913331  1831.031144  19.272614   \n",
            "              Proposed Method  2.588596  0.585317  1800.262273   1.415300   \n",
            "              Random           8.335682  0.644006  1835.106038  13.526300   \n",
            "              RoundRobin       8.957056  0.550138  1843.853931  11.139188   \n",
            "stationary    FCFS             5.033181  1.012724  1825.813006  25.857811   \n",
            "              MaxMin           9.253696  0.633551  1848.370891  59.149187   \n",
            "              MinMin           3.306027  1.344128  1809.331018   6.284076   \n",
            "              Proposed Method  2.557016  0.819341  1800.850798   4.472475   \n",
            "              Random           6.323734  0.408112  1842.801135  54.386086   \n",
            "              RoundRobin       6.731201  0.433981  1824.145502  14.467470   \n",
            "\n",
            "                                     p95           deadline_miss            \n",
            "                                    mean       std          mean       std  \n",
            "scenario      scheduler                                                     \n",
            "bursty        FCFS             19.899076  1.425044      0.005409  0.001405  \n",
            "              MaxMin           26.556689  1.342783      0.008679  0.001985  \n",
            "              MinMin           10.530322  1.696542      0.001269  0.001013  \n",
            "              Proposed Method   7.540704  1.026957      0.000601  0.000549  \n",
            "              Random           20.896898  1.516726      0.005207  0.002022  \n",
            "              RoundRobin       22.063388  1.069941      0.005875  0.001386  \n",
            "heterogeneous FCFS             19.014092  6.395908      0.004600  0.003700  \n",
            "              MaxMin           32.132430  2.526613      0.012933  0.001847  \n",
            "              MinMin           12.700929  5.507533      0.003000  0.001546  \n",
            "              Proposed Method   8.273359  3.115253      0.001133  0.000730  \n",
            "              Random           30.406113  2.271082      0.010933  0.001588  \n",
            "              RoundRobin       31.675002  1.270639      0.011200  0.000960  \n",
            "stationary    FCFS             16.926362  2.291203      0.003733  0.002074  \n",
            "              MaxMin           27.283665  1.218213      0.010000  0.000667  \n",
            "              MinMin           10.730253  4.864163      0.001667  0.001563  \n",
            "              Proposed Method   7.896797  3.077169      0.000400  0.000435  \n",
            "              Random           20.454223  1.169050      0.006000  0.001453  \n",
            "              RoundRobin       21.912848  1.100973      0.006133  0.000380  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# List the baseline schedulers, with \"Proposed Method\" to appear last\n",
        "base_schedulers = [\"FCFS\", \"RoundRobin\", \"Random\", \"MinMin\", \"MaxMin\"]\n",
        "proposed_scheduler = \"Proposed Method\"\n",
        "scheduler_order = base_schedulers + [proposed_scheduler]\n",
        "\n",
        "label_map = {x: x for x in base_schedulers}\n",
        "label_map[proposed_scheduler] = \"Proposed Method\"\n",
        "\n",
        "metrics = [\"ACT\", \"p95\", \"deadline_miss\", \"makespan\"]\n",
        "\n",
        "for sc in agg.index.get_level_values('scenario').unique():\n",
        "    sub = agg.loc[sc]\n",
        "    # Find all actually present schedulers for this scenario\n",
        "    present = list(sub.index)\n",
        "    ordered = [x for x in base_schedulers if x in present]\n",
        "    if proposed_scheduler in present:\n",
        "        ordered.append(proposed_scheduler)  # ensure last\n",
        "    # Now plot for each metric\n",
        "    for metric in metrics:\n",
        "        means = sub.loc[ordered][metric, 'mean']\n",
        "        stds = sub.loc[ordered][metric, 'std']\n",
        "        means.index = [label_map[x] for x in means.index]\n",
        "        plt.figure(figsize=(6, 4))\n",
        "        means.plot(kind=\"bar\", yerr=stds, alpha=0.7)\n",
        "        plt.ylabel(metric)\n",
        "        plt.title(f\"{sc} - {metric}\")\n",
        "        plt.tight_layout()\n",
        "        fname = f\"{sc}_{metric}.png\"\n",
        "        plt.savefig(os.path.join(CONFIG[\"RESULTS_DIR\"], fname))\n",
        "        plt.close()\n"
      ],
      "metadata": {
        "id": "ZWyIKIgZq_xJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    from google.colab import files\n",
        "    import shutil"
      ],
      "metadata": {
        "id": "3uo4k7HCLxcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    shutil.make_archive(\"/content\", 'zip', \"/content\")\n",
        "    files.download(\"/content.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "_Vrmy7wTMgGV",
        "outputId": "d08fc897-2b88-4a10-9765-b2894fc2eb01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2ff84633-6349-4977-95d9-dd7230a4ba3a\", \"content.zip\", 7270022)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# 10) Statistical Significance\n",
        "# ===============================\n",
        "\n",
        "def significance_tests(all_results,baseline=\"Random\",target=\"Hybrid\"):\n",
        "    out=[]\n",
        "    for sc in SCENARIOS:\n",
        "        sub=all_results[all_results.scenario==sc]\n",
        "        for metric in [\"ACT\",\"p95\",\"deadline_miss\"]:\n",
        "            base=sub[sub.scheduler==baseline][metric].values\n",
        "            tgt=sub[sub.scheduler==target][metric].values\n",
        "            if len(base)!=len(tgt): continue\n",
        "            # normality\n",
        "            _,p_norm=stats.shapiro(tgt-base)\n",
        "            if p_norm>0.05:\n",
        "                t,p=stats.ttest_rel(tgt,base)\n",
        "                test=\"t-test\"\n",
        "            else:\n",
        "                t,p=stats.wilcoxon(tgt,base)\n",
        "                test=\"wilcoxon\"\n",
        "            eff=(np.mean(tgt)-np.mean(base))/np.std(base)\n",
        "            out.append([sc,metric,test,p,eff])\n",
        "    return pd.DataFrame(out,columns=[\"scenario\",\"metric\",\"test\",\"pval\",\"effect\"])\n",
        "\n",
        "sig=significance_tests(all_results)\n",
        "print(sig)\n",
        "sig.to_csv(os.path.join(CONFIG[\"RESULTS_DIR\"],\"table_significance.csv\"),index=False)\n",
        "\n",
        "# LaTeX table\n",
        "with open(os.path.join(CONFIG[\"RESULTS_DIR\"],\"table_significance.tex\"),\"w\") as f:\n",
        "    f.write(sig.to_latex(index=False,float_format=\"%.3f\"))\n"
      ],
      "metadata": {
        "id": "dvJFjj9_lAFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# 11) Ablation & Robustness\n",
        "# ===============================\n",
        "\n",
        "class HybridNoCluster(HybridScheduler):\n",
        "    def cluster_vms(self):  # override to disable clustering: all VMs one cluster\n",
        "        return {vm_id: 0 for vm_id in self.sim.vms.keys()}\n",
        "\n",
        "class ClusterGreedyScheduler(BaseScheduler):\n",
        "    def __init__(self, sim, config):\n",
        "        super().__init__(sim, config)\n",
        "        self.vm_clusters = HybridScheduler.cluster_vms(self)\n",
        "    def schedule(self, now):\n",
        "        free_vms = [vm for vm in self.sim.vms.values() if vm.is_free(now)]\n",
        "        if not free_vms or not self.sim.queue:\n",
        "            return\n",
        "        for task in list(self.sim.queue):\n",
        "            # Pick VM cluster via simple heuristic\n",
        "            vm_cluster_counts = {}\n",
        "            for vm in free_vms:\n",
        "                c = self.vm_clusters[vm.vm_id]\n",
        "                vm_cluster_counts[c] = vm_cluster_counts.get(c, 0) + 1\n",
        "            best_cluster = max(vm_cluster_counts, key=vm_cluster_counts.get)\n",
        "            candidate_vms = [vm for vm in free_vms if self.vm_clusters[vm.vm_id] == best_cluster]\n",
        "            if candidate_vms:\n",
        "                vm = random.choice(candidate_vms)\n",
        "                if self.sim.start_task(task, vm, now):\n",
        "                    self.sim.queue.remove(task)\n",
        "\n",
        "class HybridNoUpdates(HybridScheduler):\n",
        "    # Offline only: disables online model refit\n",
        "    def schedule(self, now):\n",
        "        free_vms = [vm for vm in self.sim.vms.values() if vm.is_free(now)]\n",
        "        if not free_vms or not self.sim.queue:\n",
        "            return\n",
        "        if self.warmup:\n",
        "            # Warmup same as original\n",
        "            super().schedule(now)\n",
        "        else:\n",
        "            for task in list(self.sim.queue):\n",
        "                preds = []\n",
        "                for vm in free_vms:\n",
        "                    X = self.feature_vector(task, vm, now).reshape(1, -1)\n",
        "                    XT = self.scaler.transform(X)\n",
        "                    yhat = self.model.predict(XT)[0]\n",
        "                    preds.append((vm, yhat))\n",
        "                vm = min(preds, key=lambda p: p[1])[0]\n",
        "                if self.sim.start_task(task, vm, now):\n",
        "                    self.sim.queue.remove(task)\n",
        "                    # No online update here\n",
        "\n",
        "class HybridLinearSGD(HybridScheduler):\n",
        "    def __init__(self, sim, config):\n",
        "        super().__init__(sim, config)\n",
        "        self.model = SGDRegressor(max_iter=1000, tol=1e-3, random_state=config[\"SEED\"])\n",
        "        self.warmup = True\n",
        "\n",
        "# Robustness: Inject sudden latency increase and VM throttling\n",
        "\n",
        "def inject_concept_drift(sim: Simulator, drift_time=900):\n",
        "    \"\"\"At drift_time (seconds), degrade network and reduce VM perf.\"\"\"\n",
        "    def drift(env):\n",
        "        yield env.timeout(drift_time)\n",
        "        sim.net_model.base_latency = {k: v*3 for k, v in sim.net_model.base_latency.items()}\n",
        "        for vm in sim.vms.values():\n",
        "            vm.cpu_ghz *= 0.5  # simulate throttling\n",
        "        print(f\"[{env.now:.2f}] Concept drift injected: latency x3, VM CPU halved\")\n",
        "    sim.env.process(drift(sim.env))\n",
        "\n",
        "# Ablation experiments run function\n",
        "\n",
        "def run_ablation_experiments(tasks_df, vms_df, config, seeds=[1,2]):\n",
        "    ablations = {\n",
        "        \"HybridNoCluster\": HybridNoCluster,\n",
        "        \"ClusterGreedy\": ClusterGreedyScheduler,\n",
        "        \"HybridNoUpdates\": HybridNoUpdates,\n",
        "        \"HybridLinearSGD\": HybridLinearSGD,\n",
        "        \"Hybrid\": HybridScheduler,\n",
        "    }\n",
        "    results = []\n",
        "    for seed in seeds:\n",
        "        np.random.seed(seed)\n",
        "        random.seed(seed)\n",
        "        for name, cls in ablations.items():\n",
        "            sim = Simulator(tasks_df, vms_df, cls, config)\n",
        "            # Inject concept drift in robustness scenario\n",
        "            if config.get(\"ROBUSTNESS\", False):\n",
        "                inject_concept_drift(sim)\n",
        "            sim.run()\n",
        "            completion = [t.finish_time - t.arrival for t in sim.completed if t.finish_time]\n",
        "            act = np.mean(completion)\n",
        "            deadline_miss = np.mean([1 if t.deadline and t.finish_time > t.deadline else 0 for t in sim.completed])\n",
        "            results.append([seed, name, act, deadline_miss])\n",
        "    return pd.DataFrame(results, columns=[\"seed\", \"scheduler\", \"ACT\", \"deadline_miss\"])\n",
        "\n",
        "# Example robustness run (small scale)\n",
        "robust_cfg = CONFIG.copy()\n",
        "robust_cfg.update({\"NUM_TASKS\":2000, \"NUM_VMS\":30, \"RUNTIME_MINUTES\":20, \"ROBUSTNESS\": True})\n",
        "\n",
        "ablation_df = run_ablation_experiments(tasks_df.head(robust_cfg[\"NUM_TASKS\"]),\n",
        "                                      vms_df.head(robust_cfg[\"NUM_VMS\"]),\n",
        "                                      robust_cfg)\n",
        "print(ablation_df.groupby(\"scheduler\")[[\"ACT\", \"deadline_miss\"]].mean())\n"
      ],
      "metadata": {
        "id": "TsJKwwBilNys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# 12) Complexity & Throughput (Fixed)\n",
        "# ===============================\n",
        "\n",
        "import timeit\n",
        "\n",
        "def scheduler_latency_benchmark(scheduler_cls, tasks_df, vms_df, config, n_trials=5):\n",
        "    times = []\n",
        "    for _ in range(n_trials):\n",
        "        sim = Simulator(tasks_df, vms_df, scheduler_cls, config)\n",
        "        now = 0.0  # Starting simulated time\n",
        "        # Call schedule but do NOT step the SimPy env. We only want to time the decision function\n",
        "        start = timeit.default_timer()\n",
        "        sim.scheduler.schedule(now)\n",
        "        duration = (timeit.default_timer() - start) * 1000  # ms\n",
        "        times.append(duration)\n",
        "    return np.mean(times), np.std(times)\n",
        "\n",
        "\n",
        "benchmark_results = {}\n",
        "for sched_name, sched_cls in [(\"Hybrid\", HybridScheduler), (\"FCFS\", FCFS), (\"RoundRobin\", RoundRobin)]:\n",
        "    mean_t, std_t = scheduler_latency_benchmark(\n",
        "        sched_cls,\n",
        "        tasks_df.head(500), vms_df.head(50), CONFIG)\n",
        "    benchmark_results[sched_name] = (mean_t, std_t)\n",
        "\n",
        "print(\"Scheduler decision latency (ms):\", benchmark_results)\n",
        "\n",
        "# Display complexity notes as markdown\n",
        "\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "display(Markdown(r\"\"\"\n",
        "## Time Complexity of Core Scheduling Steps\n",
        "\n",
        "- **Clustering lookup:** \\(O(1)\\) per VM after pre-computed labels\n",
        "- **Candidate VM filtering:** \\(O(|V|)\\) per scheduling tick\n",
        "- **Model inference:** \\(O(|V| \\cdot f)\\) where \\(f\\) = feature dimensions (small)\n",
        "- **Candidate scoring & selection:** \\(O(|V|)\\)\n",
        "\n",
        "Overall complexity scales linearly with the number of VMs per scheduling tick, suitable for real-time scheduling in hybrid environments.\n",
        "\"\"\"))\n"
      ],
      "metadata": {
        "id": "wmVrUhcOlaPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# 13) Reproducibility & Artifacts\n",
        "# ===============================\n",
        "\n",
        "import json\n",
        "\n",
        "# Re-set global seeds for reproducibility\n",
        "np.random.seed(CONFIG[\"SEED\"])\n",
        "random.seed(CONFIG[\"SEED\"])\n",
        "\n",
        "def save_df(df, filename):\n",
        "    path = os.path.join(CONFIG[\"RESULTS_DIR\"], filename)\n",
        "    df.to_csv(path, index=False)\n",
        "    print(f\"Saved CSV: {path}\")\n",
        "\n",
        "def save_json(data, filename):\n",
        "    path = os.path.join(CONFIG[\"RESULTS_DIR\"], filename)\n",
        "    with open(path, \"w\") as f:\n",
        "        json.dump(data, f, indent=2)\n",
        "    print(f\"Saved JSON: {path}\")\n",
        "\n",
        "def save_fig(fig, filename):\n",
        "    path_png = os.path.join(CONFIG[\"RESULTS_DIR\"], filename + \".png\")\n",
        "    path_pdf = os.path.join(CONFIG[\"RESULTS_DIR\"], filename + \".pdf\")\n",
        "    fig.savefig(path_png, dpi=300)\n",
        "    fig.savefig(path_pdf)\n",
        "    print(f\"Saved figures: {path_png} and {path_pdf}\")\n",
        "\n",
        "# Save config JSON for experiment metadata\n",
        "save_json(CONFIG, \"config.json\")\n",
        "\n",
        "# Placeholders for saving example dataframe and figures from prior experiments (to be called after experiment runs)\n",
        "# save_df(all_results, \"aggregate_results.csv\")\n",
        "# save_fig(plt.gcf(), \"example_plot\")\n",
        "\n"
      ],
      "metadata": {
        "id": "PWhWKV4Jlb8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# API / Code Structure (Classes with docstrings & type hints)\n",
        "# ===============================\n",
        "\n",
        "from typing import List, Dict, Optional\n",
        "\n",
        "class Task:\n",
        "    \"\"\"Representation of a submitted compute task.\n",
        "\n",
        "    Attributes:\n",
        "        task_id: Unique task identifier.\n",
        "        arrival: Arrival time in seconds.\n",
        "        cpu_req: Required CPU cycles.\n",
        "        mem_req: Memory requirement in GB.\n",
        "        io_intensity: IO intensity [0,1].\n",
        "        input_mb: Input data size in MB.\n",
        "        deadline: Optional deadline time.\n",
        "        ilp: Instruction-level parallelism factor.\n",
        "        type: Task type label e.g., batch, interactive, ml.\n",
        "        wait_time: Time spent waiting in queue.\n",
        "        start_time: Actual start time of execution.\n",
        "        finish_time: Completion time.\n",
        "        vm_id: Assigned VM.\n",
        "    \"\"\"\n",
        "    def __init__(self, data: pd.Series):\n",
        "        self.task_id: int = data.task_id\n",
        "        self.arrival: float = data.arrival\n",
        "        self.cpu_req: float = data.cpu_req\n",
        "        self.mem_req: float = data.mem_req\n",
        "        self.io_intensity: float = data.io_intensity\n",
        "        self.input_mb: float = data.input_mb\n",
        "        self.deadline: Optional[float] = data.deadline\n",
        "        self.ilp: float = data.ilp\n",
        "        self.type: str = data.type\n",
        "\n",
        "        self.wait_time: Optional[float] = None\n",
        "        self.start_time: Optional[float] = None\n",
        "        self.finish_time: Optional[float] = None\n",
        "        self.vm_id: Optional[int] = None\n",
        "\n",
        "class VM:\n",
        "    \"\"\"Representation of a Virtual Machine resource.\n",
        "\n",
        "    Attributes:\n",
        "        vm_id: Unique VM identifier.\n",
        "        cores: Number of CPU cores.\n",
        "        cpu_ghz: CPU frequency GHz.\n",
        "        mem_gb: Memory in GB.\n",
        "        disk_iops: Disk IO operations per second.\n",
        "        arch: Architecture flag (x86/ARM).\n",
        "        loc: Location ('edge' or 'cloud').\n",
        "        busy_until: Time until which VM is busy.\n",
        "    \"\"\"\n",
        "    def __init__(self, data: pd.Series):\n",
        "        self.vm_id: int = data.vm_id\n",
        "        self.cores: int = data.cores\n",
        "        self.cpu_ghz: float = data.cpu_ghz\n",
        "        self.mem_gb: int = data.mem_gb\n",
        "        self.disk_iops: float = data.disk_iops\n",
        "        self.arch: str = data.arch\n",
        "        self.loc: str = data.loc\n",
        "\n",
        "        self.busy_until: float = 0.0\n",
        "\n",
        "    def is_free(self, now: float) -> bool:\n",
        "        return now >= self.busy_until\n",
        "\n",
        "# Other classes (NetworkModel, Simulator, HybridScheduler, BaselineSchedulers) similarly to previous cells,\n",
        "# with added type hints and docstrings.\n"
      ],
      "metadata": {
        "id": "FeP1eACArBlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "#Final Cell: Reproduce All Experiments\n",
        "# ===============================\n",
        "\n",
        "def run_all_experiments(config, scenarios, schedulers, seeds=[42, 43, 44, 45, 46]):\n",
        "    all_results = []\n",
        "    for scenario_name in scenarios:\n",
        "        print(f\"=== Running scenario: {scenario_name} ===\")\n",
        "        sc_cfg = config.copy()\n",
        "        sc_cfg.update(scenarios[scenario_name])\n",
        "        for seed in seeds:\n",
        "            print(f\"Running seed {seed}...\")\n",
        "            np.random.seed(seed)\n",
        "            random.seed(seed)\n",
        "            tasks = generate_tasks(sc_cfg[\"NUM_TASKS\"], sc_cfg[\"RUNTIME_MINUTES\"], seed)\n",
        "            vms = generate_vms(sc_cfg[\"NUM_VMS\"], seed)\n",
        "\n",
        "            for sched_name, sched_cls in schedulers.items():\n",
        "                print(f\"  Scheduler: {sched_name}\")\n",
        "                sim = Simulator(tasks, vms, sched_cls, sc_cfg)\n",
        "                sim.run()\n",
        "\n",
        "                # Compute metrics\n",
        "                completion_times = [t.finish_time - t.arrival for t in sim.completed if t.finish_time]\n",
        "                queue_waits = [t.wait_time for t in sim.completed if t.wait_time is not None]\n",
        "                deadline_miss_rate = np.mean([1 if (t.deadline and t.finish_time > t.deadline) else 0 for t in sim.completed])\n",
        "                makespan = max([t.finish_time for t in sim.completed]) - min([t.start_time for t in sim.completed])\n",
        "                act = np.mean(completion_times)\n",
        "                p95 = np.percentile(completion_times, 95)\n",
        "                mean_queue_wait = np.mean(queue_waits) if queue_waits else 0\n",
        "\n",
        "                # Cost proxy: cloud VMs cost more\n",
        "                cloud_busy_time = sum(t.compute_time for t in sim.completed if sim.vms[t.vm_id].loc == \"cloud\")\n",
        "                edge_busy_time = sum(t.compute_time for t in sim.completed if sim.vms[t.vm_id].loc == \"edge\")\n",
        "                cost = cloud_busy_time * 1.5 + edge_busy_time * 1.0  # Arbitrary cost weights\n",
        "\n",
        "                # Energy proxy: watts * busy time (simplified)\n",
        "                energy = cloud_busy_time * 120 + edge_busy_time * 50  # watts\n",
        "\n",
        "                # Save task-level records CSV\n",
        "                records = []\n",
        "                for t in sim.completed:\n",
        "                    records.append({\n",
        "                        \"task_id\": t.task_id,\n",
        "                        \"scheduler\": sched_name,\n",
        "                        \"scenario\": scenario_name,\n",
        "                        \"seed\": seed,\n",
        "                        \"wait_time\": t.wait_time,\n",
        "                        \"start_time\": t.start_time,\n",
        "                        \"finish_time\": t.finish_time,\n",
        "                        \"vm_id\": t.vm_id,\n",
        "                        \"vm_loc\": sim.vms[t.vm_id].loc,\n",
        "                        \"transfer_time\": t.transfer_time,\n",
        "                        \"compute_time\": t.compute_time,\n",
        "                        \"deadline\": t.deadline,\n",
        "                    })\n",
        "                df_tasks = pd.DataFrame(records)\n",
        "                df_tasks.to_csv(os.path.join(config[\"RESULTS_DIR\"],\n",
        "                                             f\"results_{scenario_name}_{sched_name}_seed{seed}.csv\"), index=False)\n",
        "\n",
        "                # Accumulate summary results\n",
        "                all_results.append({\n",
        "                    \"scenario\": scenario_name, \"scheduler\": sched_name, \"seed\": seed,\n",
        "                    \"ACT\": act, \"Makespan\": makespan, \"P95\": p95,\n",
        "                    \"DeadlineMissRate\": deadline_miss_rate,\n",
        "                    \"MeanQueueWait\": mean_queue_wait, \"CostProxy\": cost, \"EnergyProxy\": energy\n",
        "                })\n",
        "\n",
        "            print(f\"Completed seed {seed} for scenario {scenario_name}.\\n\")\n",
        "\n",
        "    df_all = pd.DataFrame(all_results)\n",
        "    df_all.to_csv(os.path.join(config[\"RESULTS_DIR\"], \"aggregate_results.csv\"), index=False)\n",
        "    print(\"Saved aggregate results CSV.\")\n",
        "    return df_all\n",
        "\n",
        "\n",
        "# Run all experiments with default seeds and scenarios\n",
        "df_experiments = run_all_experiments(CONFIG, SCENARIOS, SCHEDULERS)\n",
        "\n",
        "# Produce summary bar plot examples (ACT per scheduler per scenario)\n",
        "import matplotlib.pyplot as plt\n",
        "for sc in SCENARIOS.keys():\n",
        "    df_sc = df_experiments[df_experiments.scenario == sc]\n",
        "    means = df_sc.groupby(\"scheduler\")[\"ACT\"].mean()\n",
        "    stds = df_sc.groupby(\"scheduler\")[\"ACT\"].std()\n",
        "    plt.figure(figsize=(8,4))\n",
        "    means.plot(kind=\"bar\", yerr=stds, capsize=4, title=f\"Average Completion Time for {sc} scenario\")\n",
        "    plt.ylabel(\"Seconds\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(CONFIG[\"RESULTS_DIR\"], f\"bar_act_{sc}.png\"))\n",
        "    plt.close()\n",
        "\n",
        "print(\"All experiments completed, figures saved to:\", CONFIG[\"RESULTS_DIR\"])\n"
      ],
      "metadata": {
        "id": "HKQt9JU1rDNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9VAc3GtCrKum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    !zip -r /content/my_files.zip /content/\n",
        "    from google.colab import files\n",
        "    files.download('/content/my_files.zip')"
      ],
      "metadata": {
        "id": "zU1b3BJJxT-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rdcxeQnMxU-x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}